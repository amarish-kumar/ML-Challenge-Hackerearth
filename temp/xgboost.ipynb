{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as pp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/sachin/Downloads/ML Challenge Hackerearth/train_indessa.csv\")\n",
    "tf = pd.read_csv(\"/Users/sachin/Downloads/ML Challenge Hackerearth/test_indessa.csv\")\n",
    "ds = df.values\n",
    "ts = tf.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'desc'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.values[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "l=[]\n",
    "\n",
    "for ix in range(ds.shape[0]):\n",
    "    test = ds[ix]\n",
    "    l.append(np.unique(pd.isnull(test), return_counts=True)[1][1])\n",
    "    \n",
    "print l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array(['A', 'B', 'C', 'D', 'E', 'F', 'G'], \n",
      "      dtype='|S1'), array([ 836, 1402, 1393,  814,  371,  160,   24]))\n"
     ]
    }
   ],
   "source": [
    "te=[]\n",
    "\n",
    "for ix in range(5000):\n",
    "    te.append(ds[ix, 7])\n",
    "\n",
    "te = np.asarray(te)\n",
    "print np.unique(te, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "int col5=0\n",
    "\n",
    "for ix in range(10):#ds.shape[0]):\n",
    "    print (np.unique(pd.isnull(ds[ix, :]), return_counts=True))[1][1], \n",
    "    if(ds[ix, 5] == ' '):\n",
    "        print \"batch yes\",\n",
    "    if(ds[ix, 5] == ' '):\n",
    "        col5 += 1\n",
    "    if(ds[ix, 5] == ' '):\n",
    "        col5 += 1\n",
    "print ds[2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#532428\n",
    "\n",
    "for temp in range(ds.shape[1]):\n",
    "    print temp\n",
    "    print df.columns.values[temp]\n",
    "    print np.unique(pd.isnull(ds[:, temp]), return_counts=True)\n",
    "    print np.unique(ds[:, temp], return_counts=True)\n",
    "    print '-'*50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148738\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for ix in range(ds.shape[0]):\n",
    "    if(ds[ix, 1] >= 20000): #more than 20k$ loan\n",
    "        count+=1\n",
    "        \n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "member_id 24121476.5159\n",
      "loan_amnt 8434.42007952\n",
      "funded_amnt 8429.13927734\n",
      "funded_amnt_inv 8441.29038114\n",
      "term batch_enrolled int_rate 4.37961110386\n",
      "grade sub_grade emp_title emp_length home_ownership annual_inc 65199.8450138\n",
      "verification_status pymnt_plan desc purpose title zip_code addr_state dti 8.36907421811\n",
      "delinq_2yrs 0.860044949012\n",
      "inq_last_6mths 0.997025476322\n",
      "mths_since_last_delinq 21.8847973815\n",
      "mths_since_last_record 28.1392192615\n",
      "open_acc 5.31144234101\n",
      "pub_rec 0.583822181979\n",
      "revol_bal 22423.2158353\n",
      "revol_util 23.8534364988\n",
      "total_acc 11.8432108197\n",
      "initial_list_status total_rec_int 2093.19983718\n",
      "total_rec_late_fee 4.09154610039\n",
      "recoveries 409.647467093\n",
      "collection_recovery_fee 63.1233612014\n",
      "collections_12_mths_ex_med 0.133005175219\n",
      "mths_since_last_major_derog 22.1984098708\n",
      "application_type verification_status_joint last_week_pay acc_now_delinq 0.0791168064306\n",
      "tot_coll_amt 1958.57153839\n",
      "tot_cur_bal 153914.877437\n",
      "total_rev_hi_lim 38053.035312\n",
      "loan_status 0.424825584391\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "rem = []\n",
    "\n",
    "#Add constant columns as they don't help in prediction process\n",
    "for c in df.columns:\n",
    "    try:\n",
    "        print c, df[c].std()\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "print rem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forklift driver\n",
      "Truck driver\n",
      "0 member_id\n",
      "1 loan_amnt\n",
      "2 funded_amnt\n",
      "3 funded_amnt_inv\n",
      "4 term\n",
      "5 batch_enrolled\n",
      "6 int_rate\n",
      "7 grade\n",
      "8 sub_grade\n",
      "9 emp_title\n",
      "10 emp_length\n",
      "11 home_ownership\n",
      "12 annual_inc\n",
      "13 verification_status\n",
      "14 pymnt_plan\n",
      "15 desc\n",
      "16 purpose\n",
      "17 title\n",
      "18 zip_code\n",
      "19 addr_state\n",
      "20 dti\n",
      "21 delinq_2yrs\n",
      "22 inq_last_6mths\n",
      "23 mths_since_last_delinq\n",
      "24 mths_since_last_record\n",
      "25 open_acc\n",
      "26 pub_rec\n",
      "27 revol_bal\n",
      "28 revol_util\n",
      "29 total_acc\n",
      "30 initial_list_status\n",
      "31 total_rec_int\n",
      "32 total_rec_late_fee\n",
      "33 recoveries\n",
      "34 collection_recovery_fee\n",
      "35 collections_12_mths_ex_med\n",
      "36 mths_since_last_major_derog\n",
      "37 application_type\n",
      "38 verification_status_joint\n",
      "39 last_week_pay\n",
      "40 acc_now_delinq\n",
      "41 tot_coll_amt\n",
      "42 tot_cur_bal\n",
      "43 total_rev_hi_lim\n",
      "44 loan_status\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for ix in range(500):\n",
    "    try:\n",
    "        if (ds[ix, 9]).find('driver') > 0:\n",
    "            print ds[ix, 9]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "#DROP 9th\n",
    "\n",
    "for ix in range(45):\n",
    "    print ix, df.columns.values[ix]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h3>skipping 5, 9, 10, 15, 17, 21-26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h3> continous values 12, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def LabelEncoding(dataset, column_index):\n",
    "    l = pp.LabelEncoder()\n",
    "    l.fit(dataset[:, column_index])\n",
    "    var = l.transform(dataset[:, column_index])\n",
    "    return var "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#4th column, term\n",
    "term = LabelEncoding(ds, 4)\n",
    "ts_term = LabelEncoding(ts, 4)\n",
    "\n",
    "# print np.unique(term, return_counts=True)\n",
    "\n",
    "#7th column, grade\n",
    "grade = LabelEncoding(ds, 7)\n",
    "ts_grade = LabelEncoding(ts, 7)\n",
    "\n",
    "#8th column, sub_grade\n",
    "sub_grade = LabelEncoding(ds, 8)\n",
    "ts_sub_grade = LabelEncoding(ts, 8)\n",
    "\n",
    "#11th column, home_ownership\n",
    "home_ownership = LabelEncoding(ds, 11)\n",
    "ts_home_ownership = LabelEncoding(ts, 11)\n",
    "\n",
    "#13th column, verification_status\n",
    "verification_status = LabelEncoding(ds, 13)\n",
    "ts_verification_status = LabelEncoding(ts, 13)\n",
    "\n",
    "#14th column, pymnt_plan\n",
    "pymnt_plan = LabelEncoding(ds, 14)\n",
    "ts_pymnt_plan = LabelEncoding(ts, 14)\n",
    "\n",
    "#16th column, debt_consolidation\n",
    "debt_consolidation = LabelEncoding(ds, 16)\n",
    "ts_debt_consolidation = LabelEncoding(ts, 16)\n",
    "\n",
    "#18th column, zip_code\n",
    "zip_code = LabelEncoding(ds, 18)\n",
    "ts_zip_code = LabelEncoding(ts, 18)\n",
    "\n",
    "#19th column, addr_state\n",
    "addr_state = LabelEncoding(ds, 19)\n",
    "ts_addr_state = LabelEncoding(ts, 19)\n",
    "\n",
    "#30th column, initial_list_status\n",
    "initial_list_status = LabelEncoding(ds, 30)\n",
    "ts_initial_list_status = LabelEncoding(ts, 30)\n",
    "\n",
    "#37th column, application_type\n",
    "application_type = LabelEncoding(ds, 37)\n",
    "ts_application_type = LabelEncoding(ts, 37)\n",
    "\n",
    "# print np.unique(term, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = np.asarray([df['member_id'],df['loan_amnt'], df['funded_amnt'], df['funded_amnt_inv'], term, df['int_rate'],\n",
    "                 grade, sub_grade, home_ownership, verification_status, pymnt_plan, debt_consolidation, zip_code,\n",
    "                  addr_state, df['dti'], df['revol_bal'], initial_list_status, df['total_rec_int'], \n",
    "                  df['total_rec_late_fee'], df['recoveries'], df['collection_recovery_fee'], application_type])\n",
    "\n",
    "test_data = np.asarray([tf['member_id'],tf['loan_amnt'], tf['funded_amnt'], tf['funded_amnt_inv'], ts_term, \n",
    "                        tf['int_rate'], ts_grade, ts_sub_grade, ts_home_ownership, ts_verification_status, \n",
    "                        ts_pymnt_plan, ts_debt_consolidation, ts_zip_code, ts_addr_state, tf['dti'], tf['revol_bal'], \n",
    "                        ts_initial_list_status, tf['total_rec_int'],tf['total_rec_late_fee'], tf['recoveries'], \n",
    "                        tf['collection_recovery_fee'], ts_application_type])\n",
    "\n",
    "label = df['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(532428, 22) (532428,)\n",
      "(354951, 22)\n"
     ]
    }
   ],
   "source": [
    "data = data.T\n",
    "print data.shape, label.shape\n",
    "test_data = test_data.T\n",
    "print test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "split = int(0.80*data.shape[0])\n",
    "x_train = data[:split, :]\n",
    "y_train = label[:split]\n",
    "\n",
    "x_test = data[split:, :]\n",
    "y_test = label[split:]\n",
    "\n",
    "# rf = RFC(n_estimators=100, n_jobs=-1)\n",
    "\n",
    "# rf.fit(x_train, y_train)\n",
    "# print rf.score(x_test, y_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named xgboost",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-1833eb8d1bdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# estimators.append(('bag', model3))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mTQ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTQ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m55\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named xgboost"
     ]
    }
   ],
   "source": [
    "# from sklearn.ensemble import VotingClassifier as TQ\n",
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# estimators = []\n",
    "# model1 = ExtraTreesClassifier(n_jobs=-1,n_estimators=2)\n",
    "# estimators.append(('et', model1))\n",
    "# model2 = RandomForestClassifier(n_jobs=-1,n_estimators=2)\n",
    "# estimators.append(('rf', model2))\n",
    "# from sklearn.ensemble import BaggingClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# base_estimator = DecisionTreeClassifier(max_depth=13)\n",
    "# model3 = BaggingClassifier(n_jobs=-1, n_estimators=2)\n",
    "# estimators.append(('bag', model3))\n",
    "\n",
    "from xgboost import XGBClassifier as TQ\n",
    "\n",
    "clf = TQ(n_estimators=55, n_jobs=-1)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "print clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=55, n_jobs=-1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = data\n",
    "y_train = label\n",
    "\n",
    "rf = RFC(n_estimators=55, n_jobs=-1)\n",
    "\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354951,)\n"
     ]
    }
   ],
   "source": [
    "default = []\n",
    "\n",
    "ans = (rf.predict_proba(test_data))\n",
    "\n",
    "for ix in range(ans.shape[0]):\n",
    "    default.append(ans[ix][1])\n",
    "    \n",
    "default = np.asarray(default)\n",
    "print default.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "member = tf['member_id'].values\n",
    "output = np.column_stack((member, default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.181818181818\n"
     ]
    }
   ],
   "source": [
    "# np.set_printoptions(precision=2)\n",
    "print output[:5][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"./output.csv\", output, fmt=\"%.f,%.2f\", delimiter=',', header=\"member_id,loan_status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.70909091  0.29090909]]\n",
      "0.745454545455\n"
     ]
    }
   ],
   "source": [
    "print rf.predict_proba(x_test[1])\n",
    "print (rf.predict_proba(x_test[0]))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nn_label = to_categorical(label)\n",
    "nn_y_train = nn_label[:split]\n",
    "nn_y_test = nn_label[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_1 (Dense)                  (None, 256)           5888        dense_input_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 128)           32896       dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 64)            8256        dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 2)             130         dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 2)             0           dense_4[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 47,170\n",
      "Trainable params: 47,170\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(22,), activation='tanh'))\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input arrays should have the same number of samples as target arrays. Found 532428 input samples and 425942 target samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-8e943fd409e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn_y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn_y_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1114\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1117\u001b[0m         \u001b[0;31m# prepare validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1039\u001b[0m                           \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                           in zip(y, sample_weights, class_weights, self.sample_weight_modes)]\n\u001b[0;32m-> 1041\u001b[0;31m         \u001b[0mcheck_array_lengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m         \u001b[0mcheck_loss_and_target_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_functions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_output_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mcheck_array_lengths\u001b[0;34m(inputs, targets, weights)\u001b[0m\n\u001b[1;32m    191\u001b[0m                          \u001b[0;34m'the same number of samples as target arrays. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                          \u001b[0;34m'Found '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' input samples '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                          'and ' + str(list(set_y)[0]) + ' target samples.')\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         raise ValueError('Sample_weight arrays should have '\n",
      "\u001b[0;31mValueError\u001b[0m: Input arrays should have the same number of samples as target arrays. Found 532428 input samples and 425942 target samples."
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, nn_y_train, shuffle=True, batch_size=256, nb_epoch=10, validation_data=(x_test, nn_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
